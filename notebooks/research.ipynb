{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "0f9525a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b6cf63",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c6601f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download historical stock data for Apple Inc. (AAPL)\n",
    "ticker = 'AAPL' # Apple Inc.\n",
    "start_date = '2020-01-01'\n",
    "df = yf.download(ticker, start=start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "cff590fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df[\"log_return\"] = np.log(df[\"Close\"]).diff()\n",
    "df[\"target\"] = df[\"log_return\"].shift(-1)\n",
    "\n",
    "df[\"volatility_10\"] = df[\"log_return\"].rolling(10).std()\n",
    "df[\"volatility_30\"] = df[\"log_return\"].rolling(30).std()\n",
    "\n",
    "df[\"momentum_10\"] = df[\"Close\"].pct_change(10)\n",
    "df[\"momentum_30\"] = df[\"Close\"].pct_change(30)\n",
    "\n",
    "df[\"volume_z\"] = (\n",
    "    df[\"Volume\"] - df[\"Volume\"].rolling(30).mean()\n",
    ") / df[\"Volume\"].rolling(30).std()\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "910b3af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>log_return</th>\n",
       "      <th>target</th>\n",
       "      <th>volatility_10</th>\n",
       "      <th>volatility_30</th>\n",
       "      <th>momentum_10</th>\n",
       "      <th>momentum_30</th>\n",
       "      <th>volume_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.516335</td>\n",
       "      <td>78.765209</td>\n",
       "      <td>78.008919</td>\n",
       "      <td>78.465588</td>\n",
       "      <td>80113600</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.018480</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>0.084472</td>\n",
       "      <td>-1.619249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.078674</td>\n",
       "      <td>77.259894</td>\n",
       "      <td>76.017933</td>\n",
       "      <td>76.199152</td>\n",
       "      <td>152531200</td>\n",
       "      <td>-0.018480</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0.035952</td>\n",
       "      <td>0.075067</td>\n",
       "      <td>0.655929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.194969</td>\n",
       "      <td>78.424517</td>\n",
       "      <td>77.320285</td>\n",
       "      <td>77.320285</td>\n",
       "      <td>93984000</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>-0.010312</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.017369</td>\n",
       "      <td>0.082015</td>\n",
       "      <td>-1.134825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.392792</td>\n",
       "      <td>78.443866</td>\n",
       "      <td>76.887794</td>\n",
       "      <td>77.955784</td>\n",
       "      <td>100566000</td>\n",
       "      <td>-0.010312</td>\n",
       "      <td>-0.022895</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.017083</td>\n",
       "      <td>-0.001213</td>\n",
       "      <td>0.075975</td>\n",
       "      <td>-0.917206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.640991</td>\n",
       "      <td>77.429029</td>\n",
       "      <td>75.024848</td>\n",
       "      <td>76.986849</td>\n",
       "      <td>129554000</td>\n",
       "      <td>-0.022895</td>\n",
       "      <td>-0.048666</td>\n",
       "      <td>0.014527</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>-0.035107</td>\n",
       "      <td>0.034971</td>\n",
       "      <td>-0.028381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>275.652069</td>\n",
       "      <td>279.238709</td>\n",
       "      <td>272.974582</td>\n",
       "      <td>277.869995</td>\n",
       "      <td>52977400</td>\n",
       "      <td>-0.002100</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.110972</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.214674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>277.859985</td>\n",
       "      <td>280.647386</td>\n",
       "      <td>276.671095</td>\n",
       "      <td>276.860920</td>\n",
       "      <td>50453400</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>-0.011729</td>\n",
       "      <td>0.015305</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>0.121271</td>\n",
       "      <td>0.021148</td>\n",
       "      <td>0.050096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>274.619995</td>\n",
       "      <td>278.200012</td>\n",
       "      <td>271.700012</td>\n",
       "      <td>277.910004</td>\n",
       "      <td>44623400</td>\n",
       "      <td>-0.011729</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>0.015488</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.076218</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>-0.316881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>273.679993</td>\n",
       "      <td>275.369995</td>\n",
       "      <td>272.940002</td>\n",
       "      <td>274.890015</td>\n",
       "      <td>34376900</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.060658</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>-0.932591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>275.500000</td>\n",
       "      <td>280.179993</td>\n",
       "      <td>274.450012</td>\n",
       "      <td>274.700012</td>\n",
       "      <td>51931300</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>-0.051274</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>0.075331</td>\n",
       "      <td>0.007298</td>\n",
       "      <td>0.010419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1506 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        Close        High         Low        Open     Volume log_return  \\\n",
       "Ticker        AAPL        AAPL        AAPL        AAPL       AAPL              \n",
       "0        78.516335   78.765209   78.008919   78.465588   80113600   0.000246   \n",
       "1        77.078674   77.259894   76.017933   76.199152  152531200  -0.018480   \n",
       "2        78.194969   78.424517   77.320285   77.320285   93984000   0.014379   \n",
       "3        77.392792   78.443866   76.887794   77.955784  100566000  -0.010312   \n",
       "4        75.640991   77.429029   75.024848   76.986849  129554000  -0.022895   \n",
       "...            ...         ...         ...         ...        ...        ...   \n",
       "1501    275.652069  279.238709  272.974582  277.869995   52977400  -0.002100   \n",
       "1502    277.859985  280.647386  276.671095  276.860920   50453400   0.007978   \n",
       "1503    274.619995  278.200012  271.700012  277.910004   44623400  -0.011729   \n",
       "1504    273.679993  275.369995  272.940002  274.890015   34376900  -0.003429   \n",
       "1505    275.500000  280.179993  274.450012  274.700012   51931300   0.006628   \n",
       "\n",
       "Price     target volatility_10 volatility_30 momentum_10 momentum_30  volume_z  \n",
       "Ticker                                                                          \n",
       "0      -0.018480      0.014343      0.016556    0.052377    0.084472 -1.619249  \n",
       "1       0.014379      0.016060      0.016856    0.035952    0.075067  0.655929  \n",
       "2      -0.010312      0.013200      0.016969    0.017369    0.082015 -1.134825  \n",
       "3      -0.022895      0.013491      0.017083   -0.001213    0.075975 -0.917206  \n",
       "4      -0.048666      0.014527      0.017491   -0.035107    0.034971 -0.028381  \n",
       "...          ...           ...           ...         ...         ...       ...  \n",
       "1501    0.007978      0.015807      0.013791    0.110972    0.018231  0.214674  \n",
       "1502   -0.011729      0.015305      0.013833    0.121271    0.021148  0.050096  \n",
       "1503   -0.003429      0.015488      0.013986    0.076218    0.003897 -0.316881  \n",
       "1504    0.006628      0.015774      0.013998    0.060658    0.001961 -0.932591  \n",
       "1505   -0.051274      0.015100      0.014048    0.075331    0.007298  0.010419  \n",
       "\n",
       "[1506 rows x 12 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fb7e4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and target column\n",
    "FEATURE_COLS = [\n",
    "    \"volatility_10\",\n",
    "    \"volatility_30\",\n",
    "    \"momentum_10\",\n",
    "    \"momentum_30\",\n",
    "    \"volume_z\",\n",
    "]\n",
    "\n",
    "TARGET_COL = \"target\"\n",
    "SEQ_LEN = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "2b235129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "split_idx = int(len(df) * 0.7)\n",
    "\n",
    "train_df = df.iloc[:split_idx]\n",
    "test_df = df.iloc[split_idx + SEQ_LEN:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "19bad80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4656\\1918266380.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[FEATURE_COLS] = x_scaler.fit_transform(train_df[FEATURE_COLS])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4656\\1918266380.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[FEATURE_COLS] = x_scaler.transform(test_df[FEATURE_COLS])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4656\\1918266380.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[TARGET_COL] = y_scaler.fit_transform(\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4656\\1918266380.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[TARGET_COL] = y_scaler.transform(\n"
     ]
    }
   ],
   "source": [
    "# Scale features and target\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "\n",
    "train_df[FEATURE_COLS] = x_scaler.fit_transform(train_df[FEATURE_COLS])\n",
    "test_df[FEATURE_COLS] = x_scaler.transform(test_df[FEATURE_COLS])\n",
    "\n",
    "train_df[TARGET_COL] = y_scaler.fit_transform(\n",
    "    train_df[[TARGET_COL]]\n",
    ")\n",
    "test_df[TARGET_COL] = y_scaler.transform(\n",
    "    test_df[[TARGET_COL]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "5118b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, df, feature_cols, target_col, seq_len):\n",
    "        self.X = df[feature_cols].values\n",
    "        self.y = df[target_col].values\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx : idx + self.seq_len]\n",
    "        y = self.y[idx + self.seq_len]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "aa906d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_ds = SequenceDataset(train_df, FEATURE_COLS, TARGET_COL, SEQ_LEN)\n",
    "test_ds = SequenceDataset(test_df, FEATURE_COLS, TARGET_COL, SEQ_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c429155",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a49f9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b6fe7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LSTMModel(input_size=len(FEATURE_COLS)).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "a1a86f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE = 0.8117\n",
      "Epoch 2: Train MSE = 0.8047\n",
      "Epoch 3: Train MSE = 0.8036\n",
      "Epoch 4: Train MSE = 0.8033\n",
      "Epoch 5: Train MSE = 0.8028\n",
      "Epoch 6: Train MSE = 0.8022\n",
      "Epoch 7: Train MSE = 0.8016\n",
      "Epoch 8: Train MSE = 0.8010\n",
      "Epoch 9: Train MSE = 0.8002\n",
      "Epoch 10: Train MSE = 0.7994\n",
      "Epoch 11: Train MSE = 0.7985\n",
      "Epoch 12: Train MSE = 0.7974\n",
      "Epoch 13: Train MSE = 0.7962\n",
      "Epoch 14: Train MSE = 0.7949\n",
      "Epoch 15: Train MSE = 0.7933\n",
      "Epoch 16: Train MSE = 0.7926\n",
      "Epoch 17: Train MSE = 0.7947\n",
      "Epoch 18: Train MSE = 0.7913\n",
      "Epoch 19: Train MSE = 0.7892\n",
      "Epoch 20: Train MSE = 0.7880\n",
      "Epoch 21: Train MSE = 0.7902\n",
      "Epoch 22: Train MSE = 0.7883\n",
      "Epoch 23: Train MSE = 0.7880\n",
      "Epoch 24: Train MSE = 0.7839\n",
      "Epoch 25: Train MSE = 0.7829\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "EPOCHS = 25\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train MSE = {np.mean(train_losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0898c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "\n",
    "preds, trues = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        pred = model(x).cpu().numpy()\n",
    "        preds.append(pred)\n",
    "        trues.append(y.numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "trues = np.concatenate(trues)\n",
    "\n",
    "# Inverse scale\n",
    "preds_real = y_scaler.inverse_transform(preds.reshape(-1,1)).flatten()\n",
    "trues_real = y_scaler.inverse_transform(trues.reshape(-1,1)).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "9db93daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 0.7595\n"
     ]
    }
   ],
   "source": [
    "# Test MSE\n",
    "test_mse = np.mean((trues-preds)**2)\n",
    "print(f\"Test MSE = {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "0dd45a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position stats:\n",
      "  min: -0.53992736\n",
      "  max: 0.6287636\n",
      "  std: 0.14107177\n"
     ]
    }
   ],
   "source": [
    "# Volatility target for scaling (1% daily is conservative)\n",
    "vol_target = 0.01\n",
    "\n",
    "# Smooth bounded position sizing\n",
    "position = np.tanh(preds_real / vol_target)\n",
    "\n",
    "print(\"Position stats:\")\n",
    "print(\"  min:\", position.min())\n",
    "print(\"  max:\", position.max())\n",
    "print(\"  std:\", position.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "bd54dbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average daily turnover: 0.04223890200651391\n"
     ]
    }
   ],
   "source": [
    "# Cost per unit turnover (5 bps = realistic for equities)\n",
    "cost_per_trade = 0.0005\n",
    "\n",
    "# Turnover = absolute position change\n",
    "turnover = np.abs(np.diff(position, prepend=0))\n",
    "\n",
    "# Transaction costs\n",
    "costs = cost_per_trade * turnover\n",
    "\n",
    "print(\"Average daily turnover:\", turnover.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "357c376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "gross_returns = position * trues_real\n",
    "net_returns = gross_returns - costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "49a167e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PERFORMANCE ===\n",
      "RMSE: 0.018112\n",
      "Correlation: 0.0444\n",
      "Direction Accuracy: 0.4898\n",
      "Sharpe (Gross): 0.366\n",
      "Sharpe (Net): 0.305\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics\n",
    "def sharpe_ratio(returns, annualize=True):\n",
    "    if returns.std() == 0:\n",
    "        return 0.0\n",
    "    sr = returns.mean() / returns.std()\n",
    "    return sr * np.sqrt(252) if annualize else sr\n",
    "\n",
    "\n",
    "sharpe_gross = sharpe_ratio(gross_returns)\n",
    "sharpe_net = sharpe_ratio(net_returns)\n",
    "\n",
    "direction_accuracy = np.mean(\n",
    "    np.sign(position) == np.sign(trues_real)\n",
    ")\n",
    "\n",
    "rmse = np.sqrt(np.mean((preds_real - trues_real) ** 2))\n",
    "corr = np.corrcoef(preds_real, trues_real)[0, 1]\n",
    "\n",
    "print(\"\\n=== PERFORMANCE ===\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"Correlation: {corr:.4f}\")\n",
    "print(f\"Direction Accuracy: {direction_accuracy:.4f}\")\n",
    "print(f\"Sharpe (Gross): {sharpe_gross:.3f}\")\n",
    "print(f\"Sharpe (Net): {sharpe_net:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c0dd0",
   "metadata": {},
   "source": [
    "# LSTM+Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "058201aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Temporal Attention Mechanism\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.score = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, lstm_out):\n",
    "        # lstm_out: (batch, seq_len, hidden)\n",
    "        scores = self.score(lstm_out).squeeze(-1)  # (batch, seq_len)\n",
    "        weights = torch.softmax(scores, dim=1)     # stable\n",
    "        context = torch.sum(lstm_out * weights.unsqueeze(-1), dim=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "db579ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM with Attention Model\n",
    "class AttnLSTM(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.attn = TemporalAttention(hidden_size=32)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        context = self.attn(lstm_out)\n",
    "        return self.fc(context).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "fb508c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE = 0.7833\n",
      "Epoch 2: Train MSE = 0.7819\n",
      "Epoch 3: Train MSE = 0.7781\n",
      "Epoch 4: Train MSE = 0.7765\n",
      "Epoch 5: Train MSE = 0.7758\n",
      "Epoch 6: Train MSE = 0.7746\n",
      "Epoch 7: Train MSE = 0.7744\n",
      "Epoch 8: Train MSE = 0.7720\n",
      "Epoch 9: Train MSE = 0.7698\n",
      "Epoch 10: Train MSE = 0.7706\n",
      "Epoch 11: Train MSE = 0.7663\n",
      "Epoch 12: Train MSE = 0.7649\n",
      "Epoch 13: Train MSE = 0.7659\n",
      "Epoch 14: Train MSE = 0.7616\n",
      "Epoch 15: Train MSE = 0.7649\n",
      "Epoch 16: Train MSE = 0.7577\n",
      "Epoch 17: Train MSE = 0.7560\n",
      "Epoch 18: Train MSE = 0.7569\n",
      "Epoch 19: Train MSE = 0.7518\n",
      "Epoch 20: Train MSE = 0.7513\n",
      "Epoch 21: Train MSE = 0.7479\n",
      "Epoch 22: Train MSE = 0.7471\n",
      "Epoch 23: Train MSE = 0.7437\n",
      "Epoch 24: Train MSE = 0.7415\n",
      "Epoch 25: Train MSE = 0.7383\n"
     ]
    }
   ],
   "source": [
    "# Train the model with Attention\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train MSE = {np.mean(losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "befa846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "\n",
    "preds, trues = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        pred = model(x).cpu().numpy()\n",
    "        preds.append(pred)\n",
    "        trues.append(y.numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "trues = np.concatenate(trues)\n",
    "\n",
    "# Inverse scale\n",
    "preds_real = y_scaler.inverse_transform(preds.reshape(-1,1)).flatten()\n",
    "trues_real = y_scaler.inverse_transform(trues.reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "21b36a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE = 0.7474\n"
     ]
    }
   ],
   "source": [
    "# Test MSE\n",
    "test_mse = np.mean((trues-preds)**2)\n",
    "print(f\"Test MSE = {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "38df4e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position stats:\n",
      "  min: -0.8888539\n",
      "  max: 0.96449184\n",
      "  std: 0.31432658\n"
     ]
    }
   ],
   "source": [
    "# Volatility target for scaling (1% daily is conservative)\n",
    "vol_target = 0.01\n",
    "\n",
    "# Smooth bounded position sizing\n",
    "position = np.tanh(preds_real / vol_target)\n",
    "\n",
    "print(\"Position stats:\")\n",
    "print(\"  min:\", position.min())\n",
    "print(\"  max:\", position.max())\n",
    "print(\"  std:\", position.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "acfc8898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average daily turnover: 0.06904630720133095\n"
     ]
    }
   ],
   "source": [
    "# Cost per unit turnover (5 bps = realistic for equities)\n",
    "cost_per_trade = 0.0005\n",
    "\n",
    "# Turnover = absolute position change\n",
    "turnover = np.abs(np.diff(position, prepend=0))\n",
    "\n",
    "# Transaction costs\n",
    "costs = cost_per_trade * turnover\n",
    "\n",
    "print(\"Average daily turnover:\", turnover.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f144dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "gross_returns = position * trues_real\n",
    "net_returns = gross_returns - costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "c9892394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PERFORMANCE ===\n",
      "RMSE: 0.017966\n",
      "Correlation: 0.1476\n",
      "Direction Accuracy: 0.5102\n",
      "Sharpe (Gross): 1.102\n",
      "Sharpe (Net): 1.042\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics\n",
    "def sharpe_ratio(returns, annualize=True):\n",
    "    if returns.std() == 0:\n",
    "        return 0.0\n",
    "    sr = returns.mean() / returns.std()\n",
    "    return sr * np.sqrt(252) if annualize else sr\n",
    "\n",
    "\n",
    "sharpe_gross = sharpe_ratio(gross_returns)\n",
    "sharpe_net = sharpe_ratio(net_returns)\n",
    "\n",
    "direction_accuracy = np.mean(\n",
    "    np.sign(position) == np.sign(trues_real)\n",
    ")\n",
    "\n",
    "rmse = np.sqrt(np.mean((preds_real - trues_real) ** 2))\n",
    "corr = np.corrcoef(preds_real, trues_real)[0, 1]\n",
    "\n",
    "print(\"\\n=== PERFORMANCE ===\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"Correlation: {corr:.4f}\")\n",
    "print(f\"Direction Accuracy: {direction_accuracy:.4f}\")\n",
    "print(f\"Sharpe (Gross): {sharpe_gross:.3f}\")\n",
    "print(f\"Sharpe (Net): {sharpe_net:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d63f51",
   "metadata": {},
   "source": [
    "Based on RMSE, the LSTM+Attention is better. Based on Sharpe, the LSTM+Attention produces cleaner or more tradable signal. So, for the production we choose LSTM+Attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0adad",
   "metadata": {},
   "source": [
    "## Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "27ae8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_regime_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df[\"ret\"] = df[\"Close\"].pct_change()\n",
    "    df[\"vol_20\"] = df[\"ret\"].rolling(20).std()\n",
    "    df[\"vol_60_med\"] = df[\"vol_20\"].rolling(60).median()\n",
    "    df[\"vol_ok\"] = df[\"vol_20\"] < 1.2 * df[\"vol_60_med\"]\n",
    "\n",
    "    close = df[\"Close\"].iloc[:, 0]\n",
    "    df[\"ma50\"] = close.rolling(50).mean()\n",
    "    df[\"trend_strength\"] = (close - df[\"ma50\"]).abs() / df[\"ma50\"]\n",
    "    df[\"trend_ok\"] = df[\"trend_strength\"] > 0.0075\n",
    "\n",
    "    df[\"regime_ok\"] = df[\"vol_ok\"] & df[\"trend_ok\"]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "beafcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(train_df, test_df, features, target, seq_len, epochs=15):\n",
    "    x_scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    train_df[features] = x_scaler.fit_transform(train_df[features])\n",
    "    test_df[features] = x_scaler.transform(test_df[features])\n",
    "\n",
    "    train_df[target] = y_scaler.fit_transform(train_df[[target]])\n",
    "    test_df[target] = y_scaler.transform(test_df[[target]])\n",
    "\n",
    "    train_ds = SequenceDataset(train_df, features, target, seq_len)\n",
    "    test_ds = SequenceDataset(test_df, features, target, seq_len)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=False)\n",
    "    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = AttnLSTM(len(features)).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(x), y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            preds.append(model(x.to(device)).cpu().numpy())\n",
    "            trues.append(y.numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    trues = np.concatenate(trues)\n",
    "\n",
    "    preds = y_scaler.inverse_transform(preds.reshape(-1, 1)).flatten()\n",
    "    trues = y_scaler.inverse_transform(trues.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return preds, trues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "41b9becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward(df, features, target):\n",
    "    SEQ_LEN = 30\n",
    "    TRAIN = 756\n",
    "    TEST = 63\n",
    "\n",
    "    vol_target = 0.01\n",
    "    cost = 0.0005\n",
    "    eps = 1e-8\n",
    "\n",
    "    all_returns = []\n",
    "    start = 0\n",
    "\n",
    "    while start + TRAIN + TEST < len(df):\n",
    "        train_df = df.iloc[start:start + TRAIN].copy()\n",
    "        test_df  = df.iloc[start + TRAIN:start + TRAIN + TEST].copy()\n",
    "\n",
    "        preds, trues = train_and_predict(\n",
    "            train_df, test_df, features, target, SEQ_LEN\n",
    "        )\n",
    "\n",
    "        preds = np.asarray(preds, dtype=float)\n",
    "        trues = np.asarray(trues, dtype=float)\n",
    "\n",
    "        # 1️⃣ Prediction smoothing (SAFE)\n",
    "        preds = pd.Series(preds).rolling(3, min_periods=1).mean().values\n",
    "\n",
    "        # 2️⃣ Raw signal\n",
    "        raw_pos = np.tanh(preds / vol_target)\n",
    "\n",
    "        # 3️⃣ Confidence gating\n",
    "        thresh = np.nanpercentile(np.abs(preds), 60)\n",
    "        gate = np.abs(preds) > thresh\n",
    "        raw_pos *= gate.astype(float)\n",
    "\n",
    "        # 4️⃣ Volatility targeting (SAFE)\n",
    "        realized_vol = test_df[\"vol_20\"].iloc[-len(raw_pos):].values\n",
    "        realized_vol = np.nan_to_num(realized_vol, nan=vol_target, posinf=vol_target)\n",
    "        realized_vol = np.maximum(realized_vol, eps)\n",
    "\n",
    "        pos = raw_pos * (vol_target / realized_vol)\n",
    "        pos = np.clip(pos, -1, 1)\n",
    "\n",
    "        # 5️⃣ Regime filter (SAFE)\n",
    "        regime = test_df[\"regime_ok\"].iloc[-len(pos):].values\n",
    "        regime = np.nan_to_num(regime, nan=0.0)\n",
    "        pos *= regime.astype(float)\n",
    "\n",
    "        # 6️⃣ Costs\n",
    "        turnover = np.abs(np.diff(pos, prepend=0))\n",
    "        costs = cost * turnover\n",
    "\n",
    "        net_ret = pos * trues - costs\n",
    "        net_ret = np.nan_to_num(net_ret)\n",
    "\n",
    "        all_returns.append(net_ret)\n",
    "\n",
    "        start += TEST\n",
    "\n",
    "    return np.concatenate(all_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "0e90f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe(r):\n",
    "    return r.mean() / r.std() * np.sqrt(252)\n",
    "\n",
    "def max_drawdown(r):\n",
    "    cum = np.cumsum(r)\n",
    "    return (cum - np.maximum.accumulate(cum)).min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "0e44ba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WF Sharpe: 0.34100132795015486\n",
      "Max Drawdown: -0.015244392432147823\n"
     ]
    }
   ],
   "source": [
    "TRADE_START = 100\n",
    "FEATURES = FEATURE_COLS\n",
    "\n",
    "df_wf = add_regime_features(df)\n",
    "df_wf = df_wf[TRADE_START:]\n",
    "df_wf = df_wf.dropna().reset_index(drop=True)\n",
    "\n",
    "returns = walk_forward(df_wf, FEATURES, \"target\")\n",
    "\n",
    "print(\"WF Sharpe:\", sharpe(returns))\n",
    "print(\"Max Drawdown:\", max_drawdown(returns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b256d",
   "metadata": {},
   "source": [
    "## Production Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "5dea3f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Drawdown: -0.060040805297102616\n"
     ]
    }
   ],
   "source": [
    "# Production Drawdown\n",
    "cum_returns = np.cumsum(net_returns)\n",
    "running_max = np.maximum.accumulate(cum_returns)\n",
    "drawdown = cum_returns - running_max\n",
    "\n",
    "print(\"Max Drawdown:\", drawdown.min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3474ba",
   "metadata": {},
   "source": [
    "At the worst point, the strategy was down ~10.2% from its previous peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ee046ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COST SENSITIVITY CHECK===\n",
      "Cost 0.0003 → Sharpe 1.066\n",
      "Cost 0.0005 → Sharpe 1.042\n",
      "Cost 0.0010 → Sharpe 0.982\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== COST SENSITIVITY CHECK===\")\n",
    "for cost in [0.0003, 0.0005, 0.001]:\n",
    "    net = gross_returns - cost * turnover\n",
    "    print(f\"Cost {cost:.4f} → Sharpe {sharpe_ratio(net):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804463e",
   "metadata": {},
   "source": [
    "Stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ddf111c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUBPERIOD STABILITY SHARPE ===\n",
      "First half: 0.8969596013608857\n",
      "Second half: 1.7547218750295126\n"
     ]
    }
   ],
   "source": [
    "mid = len(net_returns) // 2\n",
    "\n",
    "sr_first = sharpe_ratio(net_returns[:mid])\n",
    "sr_second = sharpe_ratio(net_returns[mid:])\n",
    "\n",
    "print(\"\\n=== SUBPERIOD STABILITY SHARPE ===\")\n",
    "print(\"First half:\", sr_first)\n",
    "print(\"Second half:\", sr_second)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d691a",
   "metadata": {},
   "source": [
    "All positives, supporting production confidence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
